{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "419b97e53a9842f7ae242e4249dc3797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ee608c218b649a7916fbee284760539",
              "IPY_MODEL_2df73a2904544963a11c1fad9f813740",
              "IPY_MODEL_b94c3bfc73564bb98dc424718cec3a58"
            ],
            "layout": "IPY_MODEL_f1a37e256c084e0e80afba84994fd1a7"
          }
        },
        "0ee608c218b649a7916fbee284760539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_358569e5d3b94e3fb4522a0a35b6084e",
            "placeholder": "​",
            "style": "IPY_MODEL_2cc58540b2754481b3ac83c137c2ba29",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "2df73a2904544963a11c1fad9f813740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a67a910967024ee7a4eca678696b34c5",
            "max": 632,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43542f8f319c4812b56318ed3e71dbed",
            "value": 632
          }
        },
        "b94c3bfc73564bb98dc424718cec3a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd3c10661cfe4253a7df491f05d2335a",
            "placeholder": "​",
            "style": "IPY_MODEL_c7a0e6aa4f9b4f898ea2bfdb581e19b2",
            "value": " 632/632 [00:00&lt;00:00, 34.4kB/s]"
          }
        },
        "f1a37e256c084e0e80afba84994fd1a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "358569e5d3b94e3fb4522a0a35b6084e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cc58540b2754481b3ac83c137c2ba29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a67a910967024ee7a4eca678696b34c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43542f8f319c4812b56318ed3e71dbed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd3c10661cfe4253a7df491f05d2335a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7a0e6aa4f9b4f898ea2bfdb581e19b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efaad66443e642b8a781d2a7bdad8220": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e203b1662e64492a2057d4520fa0368",
              "IPY_MODEL_ae85c3386d5d41b1afe0efc511ff94ef",
              "IPY_MODEL_a1f4179ff58042e4bed123c98884ac0d"
            ],
            "layout": "IPY_MODEL_950d893c4a4e4311a5b1a20aa05b2b60"
          }
        },
        "3e203b1662e64492a2057d4520fa0368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_407368c5a9a746acad253726bd58809a",
            "placeholder": "​",
            "style": "IPY_MODEL_a31387adc7904ba28185a0fe8c1a78f1",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "ae85c3386d5d41b1afe0efc511ff94ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08ea5244434a483696ec055f4df09b54",
            "max": 47679974,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc60e7c734c1439caea37c4eaeb81f99",
            "value": 47679974
          }
        },
        "a1f4179ff58042e4bed123c98884ac0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b209c059ebdc4f2495392515d3645f46",
            "placeholder": "​",
            "style": "IPY_MODEL_7e30d332ebaf4ef7a5c425a859680239",
            "value": " 47.7M/47.7M [00:00&lt;00:00, 178MB/s]"
          }
        },
        "950d893c4a4e4311a5b1a20aa05b2b60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "407368c5a9a746acad253726bd58809a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a31387adc7904ba28185a0fe8c1a78f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08ea5244434a483696ec055f4df09b54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc60e7c734c1439caea37c4eaeb81f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b209c059ebdc4f2495392515d3645f46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e30d332ebaf4ef7a5c425a859680239": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9044e3e2ba7742898681f8c2cab10e1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4e3148628544961a843b296135d5fb5",
              "IPY_MODEL_3d522b73fae649dab46588e2e764aae4",
              "IPY_MODEL_c5d4790e629f4709aa45c5158ef3adf4"
            ],
            "layout": "IPY_MODEL_76d589e8d6634a7ea67920d26d5bec3e"
          }
        },
        "e4e3148628544961a843b296135d5fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b02cc6c2bb6040d1a1082311917cd293",
            "placeholder": "​",
            "style": "IPY_MODEL_9d47441331ef4c6a98cbe5e585de060a",
            "value": "100%"
          }
        },
        "3d522b73fae649dab46588e2e764aae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b7d09f100dc4e17b217a84bd767c2c1",
            "max": 13126,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d6f28e70b2247eca1ec5cfa2d36bdd7",
            "value": 13126
          }
        },
        "c5d4790e629f4709aa45c5158ef3adf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d65b8539e6de45d89b308858cf67ec22",
            "placeholder": "​",
            "style": "IPY_MODEL_967cc44586cc4c988237c34ce37cf8c6",
            "value": " 13126/13126 [1:11:38&lt;00:00,  3.46it/s]"
          }
        },
        "76d589e8d6634a7ea67920d26d5bec3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b02cc6c2bb6040d1a1082311917cd293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d47441331ef4c6a98cbe5e585de060a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b7d09f100dc4e17b217a84bd767c2c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d6f28e70b2247eca1ec5cfa2d36bdd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d65b8539e6de45d89b308858cf67ec22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "967cc44586cc4c988237c34ce37cf8c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OyxGzaxU1jy",
        "outputId": "84c6d224-738c-4277-b278-483b2a16e3f3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.18.0-py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from accelerate) (2.0.0+cu118)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate) (3.11.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate) (3.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate) (16.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.4.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.4.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL_NlmBgU3ko",
        "outputId": "89fc7ae8-9488-4e48-9bf2-020efcba1fb2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.38.1-py3-none-any.whl (104.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.38.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5HmwpqzwnMyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "357e52b5-5f6d-4263-f774-4dcbdb0adad9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'character-tokenizer'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 16 (delta 3), reused 12 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), 5.11 KiB | 1.70 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dariush-bahrami/character-tokenizer.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers"
      ],
      "metadata": {
        "id": "hkVexA2nnRQ5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "device = 'cuda'"
      ],
      "metadata": {
        "id": "z3o8b2onhooe"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import sys\n",
        "sys.path.append(\"/content/character-tokenizer\")\n",
        "from charactertokenizer import CharacterTokenizer\n",
        "\n",
        "chars = \"АаБбВвГгДдЕеЁёЖжЗзИиЙйКкЛлМмНнОоПпРрСсТтУуФфХхЦцЧчШшЩщЪъЫыЬьЭэЮюЯя\"\n",
        "model_max_length = 64\n",
        "tokenizer = CharacterTokenizer(chars, model_max_length)"
      ],
      "metadata": {
        "id": "5FaCG9ajnS_G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = \"Привет\"\n",
        "tokens = tokenizer(example)\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "I5FSPMOSncpI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "298569ea-c34c-46f4-acdd-d31ff08e7943"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [0, 39, 42, 26, 12, 18, 46, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_ids_to_tokens(tokens['input_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AioDA4WOMV66",
        "outputId": "d6a8dff6-6afd-4278-e80c-2f3c091226a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]', 'П', 'р', 'и', 'в', 'е', 'т', '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание: обучите модель классификации букв для задачи расстановки ударения с помощью методов из библиотеки transformers. Датасет для обучения можно взять отсюда: https://github.com/Koziev/NLP_Datasets/blob/master/Stress/all_accents.zip\n",
        "\n",
        "1. Напишите класс для Dataset/Dataloder и азбейте данные на случайные train / test сплиты в соотношении 50:50. (1 балл)\n",
        "2. Попробуйте несколько моделей: Bert, Albert, Deberta. (3 балла)\n",
        "Пример конфигурации для deberta: https://huggingface.co/IlyaGusev/ru-word-stress-transformer/blob/main/config.json"
      ],
      "metadata": {
        "id": "KQkp36rEoScR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip all_accents.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdTKW8M3NEpD",
        "outputId": "4e8dfcf7-92ab-4174-fe3f-4766e571d1f2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  all_accents.zip\n",
            "  inflating: all_accents.tsv         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('all_accents.tsv', delimiter='\\t')\n",
        "df.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPA_V4JqNEmx",
        "outputId": "4aa859af-355c-44e8-e80e-9d35a19e7d12"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1680534"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "gz7ORlPxNEkd",
        "outputId": "303ce30b-f563-44ee-9132-66f1dbd8d4cc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             -де                      -д^е\n",
              "1228739             протраленных             протр^аленных\n",
              "340795              донкихотство             донких^отство\n",
              "271136                 глотаемся                глот^аемся\n",
              "354249             дренажировали            дренаж^ировали\n",
              "788318   нижегороднефтеоргсинтез  нижегороднефтеоргс^интез\n",
              "701264              наващивающий             нав^ащивающий\n",
              "816974             обличительней            облич^ительней\n",
              "15089              азартничавший            аз^артничавший\n",
              "898026               отделявшему              отдел^явшему\n",
              "558661                колумбарна               колумб^арна"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-11cb709a-bcf0-4ac6-8c9b-d9c2562897ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>-де</th>\n",
              "      <th>-д^е</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1228739</th>\n",
              "      <td>протраленных</td>\n",
              "      <td>протр^аленных</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340795</th>\n",
              "      <td>донкихотство</td>\n",
              "      <td>донких^отство</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271136</th>\n",
              "      <td>глотаемся</td>\n",
              "      <td>глот^аемся</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354249</th>\n",
              "      <td>дренажировали</td>\n",
              "      <td>дренаж^ировали</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>788318</th>\n",
              "      <td>нижегороднефтеоргсинтез</td>\n",
              "      <td>нижегороднефтеоргс^интез</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701264</th>\n",
              "      <td>наващивающий</td>\n",
              "      <td>нав^ащивающий</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>816974</th>\n",
              "      <td>обличительней</td>\n",
              "      <td>облич^ительней</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15089</th>\n",
              "      <td>азартничавший</td>\n",
              "      <td>аз^артничавший</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>898026</th>\n",
              "      <td>отделявшему</td>\n",
              "      <td>отдел^явшему</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558661</th>\n",
              "      <td>колумбарна</td>\n",
              "      <td>колумб^арна</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11cb709a-bcf0-4ac6-8c9b-d9c2562897ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-11cb709a-bcf0-4ac6-8c9b-d9c2562897ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-11cb709a-bcf0-4ac6-8c9b-d9c2562897ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['target_idx'] = [word.find('^')for word in df['-д^е']]\n",
        "df.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cY9CfGjdngVw",
        "outputId": "99f590af-5d03-4901-b8cd-f06e0cc1b1fb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   -де            -д^е  target_idx\n",
              "1472510   табуизировал   табуиз^ировал           6\n",
              "620067         ликуете        лик^уете           3\n",
              "1523770  увеличиваются  увел^ичиваются           4\n",
              "1537538    укочевавший    укочев^авший           6\n",
              "1286752      раскутись      раскут^ись           6"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e57c104-b290-444e-aeb5-913a2efcb28a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>-де</th>\n",
              "      <th>-д^е</th>\n",
              "      <th>target_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1472510</th>\n",
              "      <td>табуизировал</td>\n",
              "      <td>табуиз^ировал</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>620067</th>\n",
              "      <td>ликуете</td>\n",
              "      <td>лик^уете</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1523770</th>\n",
              "      <td>увеличиваются</td>\n",
              "      <td>увел^ичиваются</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1537538</th>\n",
              "      <td>укочевавший</td>\n",
              "      <td>укочев^авший</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1286752</th>\n",
              "      <td>раскутись</td>\n",
              "      <td>раскут^ись</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e57c104-b290-444e-aeb5-913a2efcb28a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7e57c104-b290-444e-aeb5-913a2efcb28a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7e57c104-b290-444e-aeb5-913a2efcb28a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(index=np.where(df.target_idx == -1)[0], inplace=True)\n",
        "df.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4qJFVFdnxaY",
        "outputId": "c60bcca8-8195-4754-8f89-9a45dcbc76c1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1680027"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_words = df['-де']\n",
        "target = df.target_idx"
      ],
      "metadata": {
        "id": "MID6Scn_bFnQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CKOqLey3pmB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 0\n",
        "for word in train_words:\n",
        "    input_ids = tokenizer(word)['input_ids']\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "print('Max word length: ', max_len)"
      ],
      "metadata": {
        "id": "XSdd0vuuPuQ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be04937c-fbf1-41e4-b7d5-1086baa1da6e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max word length:  58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "iJzUNx__HpPv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Tokenize all of the words and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "MAX_LENGTH = max_len\n",
        "# For every sentence...\n",
        "for word in tqdm(train_words):\n",
        "    encoded_dict = tokenizer(\n",
        "                        word,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = MAX_LENGTH,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n"
      ],
      "metadata": {
        "id": "eKx2esPocWfb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the lists into tensors.\n",
        "input_ids = torch.tensor(input_ids)\n",
        "attention_masks = torch.tensor(attention_masks)\n",
        "labels = torch.tensor(target.values)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzEf3ITGsUH1",
        "outputId": "564a2fa9-40ad-459c-f84a-935774042eac"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-56dc6d930c80>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  input_ids = torch.tensor(input_ids)\n",
            "<ipython-input-37-56dc6d930c80>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  attention_masks = torch.tensor(attention_masks)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  -ка\n",
            "Token IDs: tensor([ 0,  6, 30,  8,  1,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
            "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
            "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
            "         4,  4,  4,  4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 10000\n",
        "print('Original: ', train_words[i])\n",
        "print('Token IDs:', input_ids[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxnSkzSiszkr",
        "outputId": "7ece42be-f5b9-410d-d0f7-fece92e5f288"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  агарак\n",
            "Token IDs: tensor([ 0,  8, 14,  8, 42,  8, 30,  8, 12,  8, 36,  1,  4,  4,  4,  4,  4,  4,\n",
            "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
            "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
            "         4,  4,  4,  4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "import pickle\n",
        "\n",
        "if input() == '0':\n",
        "    dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "    with open('dataset.pkl', 'wb') as f:\n",
        "        pickle.dump(dataset, f)\n",
        "else:\n",
        "    max_len = 58\n",
        "    with open('dataset.pkl', 'rb') as f:\n",
        "        dataset = pickle.load(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjjGQimsuPoO",
        "outputId": "5d613603-448e-46fe-9f24-d5749ef4e8c1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_size = int(0.5 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZGqGipTcO4R",
        "outputId": "3c63591b-e2b9-41ce-8dea-b29aa6bd3ae5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "840,013 training samples\n",
            "840,014 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "rdYv_w3wtwW4"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "iOiv0hMQcO02"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Function"
      ],
      "metadata": {
        "id": "eux_bPesjLzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "import numpy as np\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
      ],
      "metadata": {
        "id": "tsgwed4RcOql"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def train_model(model, optimizer, scheduler, epochs):\n",
        "    seed_val = 42\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    training_stats = []\n",
        "\n",
        "    total_t0 = time.time()\n",
        "\n",
        "    for epoch_i in range(0, epochs):\n",
        "        # train\n",
        "        print('\\n======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training...')\n",
        "\n",
        "        t0 = time.time()\n",
        "        total_train_loss = 0\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            if step % 100 == 0 and not step == 0:\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            model.zero_grad()        \n",
        "\n",
        "            output = model(b_input_ids, token_type_ids=None,\n",
        "                          attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "            total_train_loss += output.loss.item()\n",
        "            output.loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "        training_time = format_time(time.time() - t0)\n",
        "        print(\"\\n  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "            \n",
        "        # val\n",
        "        print(\"\\nRunning Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "        model.eval()\n",
        "\n",
        "        total_eval_accuracy = 0\n",
        "        total_eval_loss = 0\n",
        "        nb_eval_steps = 0\n",
        "\n",
        "        for batch in validation_dataloader:\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "            \n",
        "            with torch.no_grad():        \n",
        "                output = model(b_input_ids, token_type_ids=None, \n",
        "                              attention_mask=b_input_mask, labels=b_labels)\n",
        "                \n",
        "            total_eval_loss += output.loss.item()\n",
        "\n",
        "            logits = output.logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "            \n",
        "\n",
        "        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "        print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "        validation_time = format_time(time.time() - t0)\n",
        "        \n",
        "        print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "        print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Valid. Loss': avg_val_loss,\n",
        "                'Valid. Accur.': avg_val_accuracy,\n",
        "                'Training Time': training_time,\n",
        "                'Validation Time': validation_time\n",
        "            }\n",
        "        )\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "metadata": {
        "id": "q3F1KKP9esGe"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model):\n",
        "    model.eval()\n",
        "    samples = df.sample(10)\n",
        "    pred = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(10):\n",
        "            word = samples.iloc[i]['-де']\n",
        "            input = torch.tensor(tokenizer(word)['input_ids']).to(device)\n",
        "            output = model(input.unsqueeze(0))\n",
        "            preds = output.logits.detach().cpu().numpy()\n",
        "            ans = np.argmax(preds, axis=1)[0]\n",
        "            pred.append(word[:ans] + '^' + word[ans:])\n",
        "    samples['prediction'] = pred\n",
        "    samples['is_right'] = [int(inp == out) for inp, out in zip(samples['-д^е'], pred)]\n",
        "    return samples"
      ],
      "metadata": {
        "id": "G_g2LOK3esB6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT"
      ],
      "metadata": {
        "id": "d_Q_Rf2rjRxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"cointegrated/rubert-tiny\", \n",
        "    num_labels = max_len - 1,   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "model.to(device)\n",
        "optimizer = AdamW(model.parameters(),lr = 2e-5, eps = 1e-8)\n",
        "\n",
        "epochs = 4\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "419b97e53a9842f7ae242e4249dc3797",
            "0ee608c218b649a7916fbee284760539",
            "2df73a2904544963a11c1fad9f813740",
            "b94c3bfc73564bb98dc424718cec3a58",
            "f1a37e256c084e0e80afba84994fd1a7",
            "358569e5d3b94e3fb4522a0a35b6084e",
            "2cc58540b2754481b3ac83c137c2ba29",
            "a67a910967024ee7a4eca678696b34c5",
            "43542f8f319c4812b56318ed3e71dbed",
            "bd3c10661cfe4253a7df491f05d2335a",
            "c7a0e6aa4f9b4f898ea2bfdb581e19b2",
            "efaad66443e642b8a781d2a7bdad8220",
            "3e203b1662e64492a2057d4520fa0368",
            "ae85c3386d5d41b1afe0efc511ff94ef",
            "a1f4179ff58042e4bed123c98884ac0d",
            "950d893c4a4e4311a5b1a20aa05b2b60",
            "407368c5a9a746acad253726bd58809a",
            "a31387adc7904ba28185a0fe8c1a78f1",
            "08ea5244434a483696ec055f4df09b54",
            "dc60e7c734c1439caea37c4eaeb81f99",
            "b209c059ebdc4f2495392515d3645f46",
            "7e30d332ebaf4ef7a5c425a859680239"
          ]
        },
        "id": "DBBP-Hd2cOxb",
        "outputId": "46feb152-84a5-4742-c333-c0f7cdccfb25"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/632 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "419b97e53a9842f7ae242e4249dc3797"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/47.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efaad66443e642b8a781d2a7bdad8220"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, optimizer, scheduler, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zX2hY5T-esEE",
        "outputId": "0dd671c2-6b9b-4970-8b5f-5bded7bc5190"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  3,282.    Elapsed: 0:00:04.\n",
            "  Batch    80  of  3,282.    Elapsed: 0:00:08.\n",
            "  Batch   120  of  3,282.    Elapsed: 0:00:11.\n",
            "  Batch   160  of  3,282.    Elapsed: 0:00:15.\n",
            "  Batch   200  of  3,282.    Elapsed: 0:00:19.\n",
            "  Batch   240  of  3,282.    Elapsed: 0:00:23.\n",
            "  Batch   280  of  3,282.    Elapsed: 0:00:27.\n",
            "  Batch   320  of  3,282.    Elapsed: 0:00:31.\n",
            "  Batch   360  of  3,282.    Elapsed: 0:00:35.\n",
            "  Batch   400  of  3,282.    Elapsed: 0:00:39.\n",
            "  Batch   440  of  3,282.    Elapsed: 0:00:43.\n",
            "  Batch   480  of  3,282.    Elapsed: 0:00:46.\n",
            "  Batch   520  of  3,282.    Elapsed: 0:00:50.\n",
            "  Batch   560  of  3,282.    Elapsed: 0:00:54.\n",
            "  Batch   600  of  3,282.    Elapsed: 0:00:58.\n",
            "  Batch   640  of  3,282.    Elapsed: 0:01:02.\n",
            "  Batch   680  of  3,282.    Elapsed: 0:01:06.\n",
            "  Batch   720  of  3,282.    Elapsed: 0:01:10.\n",
            "  Batch   760  of  3,282.    Elapsed: 0:01:14.\n",
            "  Batch   800  of  3,282.    Elapsed: 0:01:18.\n",
            "  Batch   840  of  3,282.    Elapsed: 0:01:22.\n",
            "  Batch   880  of  3,282.    Elapsed: 0:01:26.\n",
            "  Batch   920  of  3,282.    Elapsed: 0:01:30.\n",
            "  Batch   960  of  3,282.    Elapsed: 0:01:34.\n",
            "  Batch 1,000  of  3,282.    Elapsed: 0:01:38.\n",
            "  Batch 1,040  of  3,282.    Elapsed: 0:01:42.\n",
            "  Batch 1,080  of  3,282.    Elapsed: 0:01:46.\n",
            "  Batch 1,120  of  3,282.    Elapsed: 0:01:50.\n",
            "  Batch 1,160  of  3,282.    Elapsed: 0:01:54.\n",
            "  Batch 1,200  of  3,282.    Elapsed: 0:01:58.\n",
            "  Batch 1,240  of  3,282.    Elapsed: 0:02:02.\n",
            "  Batch 1,280  of  3,282.    Elapsed: 0:02:06.\n",
            "  Batch 1,320  of  3,282.    Elapsed: 0:02:10.\n",
            "  Batch 1,360  of  3,282.    Elapsed: 0:02:14.\n",
            "  Batch 1,400  of  3,282.    Elapsed: 0:02:18.\n",
            "  Batch 1,440  of  3,282.    Elapsed: 0:02:22.\n",
            "  Batch 1,480  of  3,282.    Elapsed: 0:02:26.\n",
            "  Batch 1,520  of  3,282.    Elapsed: 0:02:30.\n",
            "  Batch 1,560  of  3,282.    Elapsed: 0:02:34.\n",
            "  Batch 1,600  of  3,282.    Elapsed: 0:02:38.\n",
            "  Batch 1,640  of  3,282.    Elapsed: 0:02:43.\n",
            "  Batch 1,680  of  3,282.    Elapsed: 0:02:47.\n",
            "  Batch 1,720  of  3,282.    Elapsed: 0:02:51.\n",
            "  Batch 1,760  of  3,282.    Elapsed: 0:02:55.\n",
            "  Batch 1,800  of  3,282.    Elapsed: 0:02:59.\n",
            "  Batch 1,840  of  3,282.    Elapsed: 0:03:03.\n",
            "  Batch 1,880  of  3,282.    Elapsed: 0:03:07.\n",
            "  Batch 1,920  of  3,282.    Elapsed: 0:03:11.\n",
            "  Batch 1,960  of  3,282.    Elapsed: 0:03:15.\n",
            "  Batch 2,000  of  3,282.    Elapsed: 0:03:19.\n",
            "  Batch 2,040  of  3,282.    Elapsed: 0:03:24.\n",
            "  Batch 2,080  of  3,282.    Elapsed: 0:03:28.\n",
            "  Batch 2,120  of  3,282.    Elapsed: 0:03:32.\n",
            "  Batch 2,160  of  3,282.    Elapsed: 0:03:36.\n",
            "  Batch 2,200  of  3,282.    Elapsed: 0:03:40.\n",
            "  Batch 2,240  of  3,282.    Elapsed: 0:03:44.\n",
            "  Batch 2,280  of  3,282.    Elapsed: 0:03:48.\n",
            "  Batch 2,320  of  3,282.    Elapsed: 0:03:52.\n",
            "  Batch 2,360  of  3,282.    Elapsed: 0:03:56.\n",
            "  Batch 2,400  of  3,282.    Elapsed: 0:04:00.\n",
            "  Batch 2,440  of  3,282.    Elapsed: 0:04:05.\n",
            "  Batch 2,480  of  3,282.    Elapsed: 0:04:09.\n",
            "  Batch 2,520  of  3,282.    Elapsed: 0:04:13.\n",
            "  Batch 2,560  of  3,282.    Elapsed: 0:04:17.\n",
            "  Batch 2,600  of  3,282.    Elapsed: 0:04:21.\n",
            "  Batch 2,640  of  3,282.    Elapsed: 0:04:25.\n",
            "  Batch 2,680  of  3,282.    Elapsed: 0:04:30.\n",
            "  Batch 2,720  of  3,282.    Elapsed: 0:04:34.\n",
            "  Batch 2,760  of  3,282.    Elapsed: 0:04:38.\n",
            "  Batch 2,800  of  3,282.    Elapsed: 0:04:42.\n",
            "  Batch 2,840  of  3,282.    Elapsed: 0:04:46.\n",
            "  Batch 2,880  of  3,282.    Elapsed: 0:04:50.\n",
            "  Batch 2,920  of  3,282.    Elapsed: 0:04:54.\n",
            "  Batch 2,960  of  3,282.    Elapsed: 0:04:59.\n",
            "  Batch 3,000  of  3,282.    Elapsed: 0:05:03.\n",
            "  Batch 3,040  of  3,282.    Elapsed: 0:05:07.\n",
            "  Batch 3,080  of  3,282.    Elapsed: 0:05:11.\n",
            "  Batch 3,120  of  3,282.    Elapsed: 0:05:15.\n",
            "  Batch 3,160  of  3,282.    Elapsed: 0:05:19.\n",
            "  Batch 3,200  of  3,282.    Elapsed: 0:05:24.\n",
            "  Batch 3,240  of  3,282.    Elapsed: 0:05:28.\n",
            "  Batch 3,280  of  3,282.    Elapsed: 0:05:32.\n",
            "\n",
            "  Average training loss: 1.71\n",
            "  Training epcoh took: 0:05:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.64\n",
            "  Validation Loss: 1.26\n",
            "  Validation took: 0:02:11\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  3,282.    Elapsed: 0:00:04.\n",
            "  Batch    80  of  3,282.    Elapsed: 0:00:08.\n",
            "  Batch   120  of  3,282.    Elapsed: 0:00:13.\n",
            "  Batch   160  of  3,282.    Elapsed: 0:00:17.\n",
            "  Batch   200  of  3,282.    Elapsed: 0:00:21.\n",
            "  Batch   240  of  3,282.    Elapsed: 0:00:25.\n",
            "  Batch   280  of  3,282.    Elapsed: 0:00:29.\n",
            "  Batch   320  of  3,282.    Elapsed: 0:00:33.\n",
            "  Batch   360  of  3,282.    Elapsed: 0:00:37.\n",
            "  Batch   400  of  3,282.    Elapsed: 0:00:42.\n",
            "  Batch   440  of  3,282.    Elapsed: 0:00:46.\n",
            "  Batch   480  of  3,282.    Elapsed: 0:00:50.\n",
            "  Batch   520  of  3,282.    Elapsed: 0:00:54.\n",
            "  Batch   560  of  3,282.    Elapsed: 0:00:59.\n",
            "  Batch   600  of  3,282.    Elapsed: 0:01:03.\n",
            "  Batch   640  of  3,282.    Elapsed: 0:01:07.\n",
            "  Batch   680  of  3,282.    Elapsed: 0:01:11.\n",
            "  Batch   720  of  3,282.    Elapsed: 0:01:15.\n",
            "  Batch   760  of  3,282.    Elapsed: 0:01:19.\n",
            "  Batch   800  of  3,282.    Elapsed: 0:01:23.\n",
            "  Batch   840  of  3,282.    Elapsed: 0:01:28.\n",
            "  Batch   880  of  3,282.    Elapsed: 0:01:32.\n",
            "  Batch   920  of  3,282.    Elapsed: 0:01:36.\n",
            "  Batch   960  of  3,282.    Elapsed: 0:01:40.\n",
            "  Batch 1,000  of  3,282.    Elapsed: 0:01:44.\n",
            "  Batch 1,040  of  3,282.    Elapsed: 0:01:48.\n",
            "  Batch 1,080  of  3,282.    Elapsed: 0:01:52.\n",
            "  Batch 1,120  of  3,282.    Elapsed: 0:01:57.\n",
            "  Batch 1,160  of  3,282.    Elapsed: 0:02:01.\n",
            "  Batch 1,200  of  3,282.    Elapsed: 0:02:05.\n",
            "  Batch 1,240  of  3,282.    Elapsed: 0:02:09.\n",
            "  Batch 1,280  of  3,282.    Elapsed: 0:02:13.\n",
            "  Batch 1,320  of  3,282.    Elapsed: 0:02:17.\n",
            "  Batch 1,360  of  3,282.    Elapsed: 0:02:21.\n",
            "  Batch 1,400  of  3,282.    Elapsed: 0:02:26.\n",
            "  Batch 1,440  of  3,282.    Elapsed: 0:02:30.\n",
            "  Batch 1,480  of  3,282.    Elapsed: 0:02:34.\n",
            "  Batch 1,520  of  3,282.    Elapsed: 0:02:38.\n",
            "  Batch 1,560  of  3,282.    Elapsed: 0:02:42.\n",
            "  Batch 1,600  of  3,282.    Elapsed: 0:02:46.\n",
            "  Batch 1,640  of  3,282.    Elapsed: 0:02:50.\n",
            "  Batch 1,680  of  3,282.    Elapsed: 0:02:55.\n",
            "  Batch 1,720  of  3,282.    Elapsed: 0:02:59.\n",
            "  Batch 1,760  of  3,282.    Elapsed: 0:03:03.\n",
            "  Batch 1,800  of  3,282.    Elapsed: 0:03:07.\n",
            "  Batch 1,840  of  3,282.    Elapsed: 0:03:11.\n",
            "  Batch 1,880  of  3,282.    Elapsed: 0:03:15.\n",
            "  Batch 1,920  of  3,282.    Elapsed: 0:03:19.\n",
            "  Batch 1,960  of  3,282.    Elapsed: 0:03:24.\n",
            "  Batch 2,000  of  3,282.    Elapsed: 0:03:28.\n",
            "  Batch 2,040  of  3,282.    Elapsed: 0:03:32.\n",
            "  Batch 2,080  of  3,282.    Elapsed: 0:03:36.\n",
            "  Batch 2,120  of  3,282.    Elapsed: 0:03:40.\n",
            "  Batch 2,160  of  3,282.    Elapsed: 0:03:44.\n",
            "  Batch 2,200  of  3,282.    Elapsed: 0:03:48.\n",
            "  Batch 2,240  of  3,282.    Elapsed: 0:03:53.\n",
            "  Batch 2,280  of  3,282.    Elapsed: 0:03:57.\n",
            "  Batch 2,320  of  3,282.    Elapsed: 0:04:01.\n",
            "  Batch 2,360  of  3,282.    Elapsed: 0:04:05.\n",
            "  Batch 2,400  of  3,282.    Elapsed: 0:04:09.\n",
            "  Batch 2,440  of  3,282.    Elapsed: 0:04:13.\n",
            "  Batch 2,480  of  3,282.    Elapsed: 0:04:17.\n",
            "  Batch 2,520  of  3,282.    Elapsed: 0:04:22.\n",
            "  Batch 2,560  of  3,282.    Elapsed: 0:04:26.\n",
            "  Batch 2,600  of  3,282.    Elapsed: 0:04:30.\n",
            "  Batch 2,640  of  3,282.    Elapsed: 0:04:34.\n",
            "  Batch 2,680  of  3,282.    Elapsed: 0:04:38.\n",
            "  Batch 2,720  of  3,282.    Elapsed: 0:04:42.\n",
            "  Batch 2,760  of  3,282.    Elapsed: 0:04:46.\n",
            "  Batch 2,800  of  3,282.    Elapsed: 0:04:51.\n",
            "  Batch 2,840  of  3,282.    Elapsed: 0:04:55.\n",
            "  Batch 2,880  of  3,282.    Elapsed: 0:04:59.\n",
            "  Batch 2,920  of  3,282.    Elapsed: 0:05:03.\n",
            "  Batch 2,960  of  3,282.    Elapsed: 0:05:08.\n",
            "  Batch 3,000  of  3,282.    Elapsed: 0:05:12.\n",
            "  Batch 3,040  of  3,282.    Elapsed: 0:05:16.\n",
            "  Batch 3,080  of  3,282.    Elapsed: 0:05:20.\n",
            "  Batch 3,120  of  3,282.    Elapsed: 0:05:24.\n",
            "  Batch 3,160  of  3,282.    Elapsed: 0:05:28.\n",
            "  Batch 3,200  of  3,282.    Elapsed: 0:05:32.\n",
            "  Batch 3,240  of  3,282.    Elapsed: 0:05:37.\n",
            "  Batch 3,280  of  3,282.    Elapsed: 0:05:41.\n",
            "\n",
            "  Average training loss: 1.08\n",
            "  Training epcoh took: 0:05:41\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.76\n",
            "  Validation Loss: 0.76\n",
            "  Validation took: 0:02:12\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  3,282.    Elapsed: 0:00:04.\n",
            "  Batch    80  of  3,282.    Elapsed: 0:00:08.\n",
            "  Batch   120  of  3,282.    Elapsed: 0:00:13.\n",
            "  Batch   160  of  3,282.    Elapsed: 0:00:17.\n",
            "  Batch   200  of  3,282.    Elapsed: 0:00:21.\n",
            "  Batch   240  of  3,282.    Elapsed: 0:00:25.\n",
            "  Batch   280  of  3,282.    Elapsed: 0:00:29.\n",
            "  Batch   320  of  3,282.    Elapsed: 0:00:33.\n",
            "  Batch   360  of  3,282.    Elapsed: 0:00:37.\n",
            "  Batch   400  of  3,282.    Elapsed: 0:00:42.\n",
            "  Batch   440  of  3,282.    Elapsed: 0:00:46.\n",
            "  Batch   480  of  3,282.    Elapsed: 0:00:50.\n",
            "  Batch   520  of  3,282.    Elapsed: 0:00:54.\n",
            "  Batch   560  of  3,282.    Elapsed: 0:00:58.\n",
            "  Batch   600  of  3,282.    Elapsed: 0:01:02.\n",
            "  Batch   640  of  3,282.    Elapsed: 0:01:07.\n",
            "  Batch   680  of  3,282.    Elapsed: 0:01:11.\n",
            "  Batch   720  of  3,282.    Elapsed: 0:01:15.\n",
            "  Batch   760  of  3,282.    Elapsed: 0:01:19.\n",
            "  Batch   800  of  3,282.    Elapsed: 0:01:23.\n",
            "  Batch   840  of  3,282.    Elapsed: 0:01:28.\n",
            "  Batch   880  of  3,282.    Elapsed: 0:01:32.\n",
            "  Batch   920  of  3,282.    Elapsed: 0:01:37.\n",
            "  Batch   960  of  3,282.    Elapsed: 0:01:41.\n",
            "  Batch 1,000  of  3,282.    Elapsed: 0:01:45.\n",
            "  Batch 1,040  of  3,282.    Elapsed: 0:01:49.\n",
            "  Batch 1,080  of  3,282.    Elapsed: 0:01:53.\n",
            "  Batch 1,120  of  3,282.    Elapsed: 0:01:58.\n",
            "  Batch 1,160  of  3,282.    Elapsed: 0:02:02.\n",
            "  Batch 1,200  of  3,282.    Elapsed: 0:02:06.\n",
            "  Batch 1,240  of  3,282.    Elapsed: 0:02:11.\n",
            "  Batch 1,280  of  3,282.    Elapsed: 0:02:15.\n",
            "  Batch 1,320  of  3,282.    Elapsed: 0:02:19.\n",
            "  Batch 1,360  of  3,282.    Elapsed: 0:02:23.\n",
            "  Batch 1,400  of  3,282.    Elapsed: 0:02:27.\n",
            "  Batch 1,440  of  3,282.    Elapsed: 0:02:32.\n",
            "  Batch 1,480  of  3,282.    Elapsed: 0:02:36.\n",
            "  Batch 1,520  of  3,282.    Elapsed: 0:02:41.\n",
            "  Batch 1,560  of  3,282.    Elapsed: 0:02:45.\n",
            "  Batch 1,600  of  3,282.    Elapsed: 0:02:49.\n",
            "  Batch 1,640  of  3,282.    Elapsed: 0:02:53.\n",
            "  Batch 1,680  of  3,282.    Elapsed: 0:02:58.\n",
            "  Batch 1,720  of  3,282.    Elapsed: 0:03:02.\n",
            "  Batch 1,760  of  3,282.    Elapsed: 0:03:06.\n",
            "  Batch 1,800  of  3,282.    Elapsed: 0:03:10.\n",
            "  Batch 1,840  of  3,282.    Elapsed: 0:03:14.\n",
            "  Batch 1,880  of  3,282.    Elapsed: 0:03:18.\n",
            "  Batch 1,920  of  3,282.    Elapsed: 0:03:23.\n",
            "  Batch 1,960  of  3,282.    Elapsed: 0:03:28.\n",
            "  Batch 2,000  of  3,282.    Elapsed: 0:03:32.\n",
            "  Batch 2,040  of  3,282.    Elapsed: 0:03:36.\n",
            "  Batch 2,080  of  3,282.    Elapsed: 0:03:40.\n",
            "  Batch 2,120  of  3,282.    Elapsed: 0:03:45.\n",
            "  Batch 2,160  of  3,282.    Elapsed: 0:03:49.\n",
            "  Batch 2,200  of  3,282.    Elapsed: 0:03:53.\n",
            "  Batch 2,240  of  3,282.    Elapsed: 0:03:58.\n",
            "  Batch 2,280  of  3,282.    Elapsed: 0:04:02.\n",
            "  Batch 2,320  of  3,282.    Elapsed: 0:04:06.\n",
            "  Batch 2,360  of  3,282.    Elapsed: 0:04:11.\n",
            "  Batch 2,400  of  3,282.    Elapsed: 0:04:15.\n",
            "  Batch 2,440  of  3,282.    Elapsed: 0:04:19.\n",
            "  Batch 2,480  of  3,282.    Elapsed: 0:04:23.\n",
            "  Batch 2,520  of  3,282.    Elapsed: 0:04:28.\n",
            "  Batch 2,560  of  3,282.    Elapsed: 0:04:32.\n",
            "  Batch 2,600  of  3,282.    Elapsed: 0:04:36.\n",
            "  Batch 2,640  of  3,282.    Elapsed: 0:04:41.\n",
            "  Batch 2,680  of  3,282.    Elapsed: 0:04:45.\n",
            "  Batch 2,720  of  3,282.    Elapsed: 0:04:49.\n",
            "  Batch 2,760  of  3,282.    Elapsed: 0:04:53.\n",
            "  Batch 2,800  of  3,282.    Elapsed: 0:04:57.\n",
            "  Batch 2,840  of  3,282.    Elapsed: 0:05:02.\n",
            "  Batch 2,880  of  3,282.    Elapsed: 0:05:06.\n",
            "  Batch 2,920  of  3,282.    Elapsed: 0:05:11.\n",
            "  Batch 2,960  of  3,282.    Elapsed: 0:05:15.\n",
            "  Batch 3,000  of  3,282.    Elapsed: 0:05:20.\n",
            "  Batch 3,040  of  3,282.    Elapsed: 0:05:24.\n",
            "  Batch 3,080  of  3,282.    Elapsed: 0:05:28.\n",
            "  Batch 3,120  of  3,282.    Elapsed: 0:05:32.\n",
            "  Batch 3,160  of  3,282.    Elapsed: 0:05:37.\n",
            "  Batch 3,200  of  3,282.    Elapsed: 0:05:41.\n",
            "  Batch 3,240  of  3,282.    Elapsed: 0:05:46.\n",
            "  Batch 3,280  of  3,282.    Elapsed: 0:05:50.\n",
            "\n",
            "  Average training loss: 0.77\n",
            "  Training epcoh took: 0:05:50\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.65\n",
            "  Validation took: 0:02:14\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  3,282.    Elapsed: 0:00:04.\n",
            "  Batch    80  of  3,282.    Elapsed: 0:00:08.\n",
            "  Batch   120  of  3,282.    Elapsed: 0:00:13.\n",
            "  Batch   160  of  3,282.    Elapsed: 0:00:17.\n",
            "  Batch   200  of  3,282.    Elapsed: 0:00:21.\n",
            "  Batch   240  of  3,282.    Elapsed: 0:00:25.\n",
            "  Batch   280  of  3,282.    Elapsed: 0:00:29.\n",
            "  Batch   320  of  3,282.    Elapsed: 0:00:33.\n",
            "  Batch   360  of  3,282.    Elapsed: 0:00:37.\n",
            "  Batch   400  of  3,282.    Elapsed: 0:00:42.\n",
            "  Batch   440  of  3,282.    Elapsed: 0:00:46.\n",
            "  Batch   480  of  3,282.    Elapsed: 0:00:50.\n",
            "  Batch   520  of  3,282.    Elapsed: 0:00:54.\n",
            "  Batch   560  of  3,282.    Elapsed: 0:00:58.\n",
            "  Batch   600  of  3,282.    Elapsed: 0:01:02.\n",
            "  Batch   640  of  3,282.    Elapsed: 0:01:07.\n",
            "  Batch   680  of  3,282.    Elapsed: 0:01:11.\n",
            "  Batch   720  of  3,282.    Elapsed: 0:01:16.\n",
            "  Batch   760  of  3,282.    Elapsed: 0:01:20.\n",
            "  Batch   800  of  3,282.    Elapsed: 0:01:24.\n",
            "  Batch   840  of  3,282.    Elapsed: 0:01:28.\n",
            "  Batch   880  of  3,282.    Elapsed: 0:01:33.\n",
            "  Batch   920  of  3,282.    Elapsed: 0:01:37.\n",
            "  Batch   960  of  3,282.    Elapsed: 0:01:41.\n",
            "  Batch 1,000  of  3,282.    Elapsed: 0:01:45.\n",
            "  Batch 1,040  of  3,282.    Elapsed: 0:01:49.\n",
            "  Batch 1,080  of  3,282.    Elapsed: 0:01:54.\n",
            "  Batch 1,120  of  3,282.    Elapsed: 0:01:58.\n",
            "  Batch 1,160  of  3,282.    Elapsed: 0:02:02.\n",
            "  Batch 1,200  of  3,282.    Elapsed: 0:02:06.\n",
            "  Batch 1,240  of  3,282.    Elapsed: 0:02:11.\n",
            "  Batch 1,280  of  3,282.    Elapsed: 0:02:15.\n",
            "  Batch 1,320  of  3,282.    Elapsed: 0:02:19.\n",
            "  Batch 1,360  of  3,282.    Elapsed: 0:02:23.\n",
            "  Batch 1,400  of  3,282.    Elapsed: 0:02:27.\n",
            "  Batch 1,440  of  3,282.    Elapsed: 0:02:31.\n",
            "  Batch 1,480  of  3,282.    Elapsed: 0:02:35.\n",
            "  Batch 1,520  of  3,282.    Elapsed: 0:02:39.\n",
            "  Batch 1,560  of  3,282.    Elapsed: 0:02:44.\n",
            "  Batch 1,600  of  3,282.    Elapsed: 0:02:48.\n",
            "  Batch 1,640  of  3,282.    Elapsed: 0:02:52.\n",
            "  Batch 1,680  of  3,282.    Elapsed: 0:02:56.\n",
            "  Batch 1,720  of  3,282.    Elapsed: 0:03:00.\n",
            "  Batch 1,760  of  3,282.    Elapsed: 0:03:04.\n",
            "  Batch 1,800  of  3,282.    Elapsed: 0:03:08.\n",
            "  Batch 1,840  of  3,282.    Elapsed: 0:03:13.\n",
            "  Batch 1,880  of  3,282.    Elapsed: 0:03:17.\n",
            "  Batch 1,920  of  3,282.    Elapsed: 0:03:21.\n",
            "  Batch 1,960  of  3,282.    Elapsed: 0:03:25.\n",
            "  Batch 2,000  of  3,282.    Elapsed: 0:03:29.\n",
            "  Batch 2,040  of  3,282.    Elapsed: 0:03:33.\n",
            "  Batch 2,080  of  3,282.    Elapsed: 0:03:37.\n",
            "  Batch 2,120  of  3,282.    Elapsed: 0:03:41.\n",
            "  Batch 2,160  of  3,282.    Elapsed: 0:03:46.\n",
            "  Batch 2,200  of  3,282.    Elapsed: 0:03:50.\n",
            "  Batch 2,240  of  3,282.    Elapsed: 0:03:54.\n",
            "  Batch 2,280  of  3,282.    Elapsed: 0:03:58.\n",
            "  Batch 2,320  of  3,282.    Elapsed: 0:04:02.\n",
            "  Batch 2,360  of  3,282.    Elapsed: 0:04:06.\n",
            "  Batch 2,400  of  3,282.    Elapsed: 0:04:10.\n",
            "  Batch 2,440  of  3,282.    Elapsed: 0:04:15.\n",
            "  Batch 2,480  of  3,282.    Elapsed: 0:04:19.\n",
            "  Batch 2,520  of  3,282.    Elapsed: 0:04:23.\n",
            "  Batch 2,560  of  3,282.    Elapsed: 0:04:27.\n",
            "  Batch 2,600  of  3,282.    Elapsed: 0:04:31.\n",
            "  Batch 2,640  of  3,282.    Elapsed: 0:04:35.\n",
            "  Batch 2,680  of  3,282.    Elapsed: 0:04:39.\n",
            "  Batch 2,720  of  3,282.    Elapsed: 0:04:44.\n",
            "  Batch 2,760  of  3,282.    Elapsed: 0:04:48.\n",
            "  Batch 2,800  of  3,282.    Elapsed: 0:04:52.\n",
            "  Batch 2,840  of  3,282.    Elapsed: 0:04:56.\n",
            "  Batch 2,880  of  3,282.    Elapsed: 0:05:00.\n",
            "  Batch 2,920  of  3,282.    Elapsed: 0:05:04.\n",
            "  Batch 2,960  of  3,282.    Elapsed: 0:05:08.\n",
            "  Batch 3,000  of  3,282.    Elapsed: 0:05:13.\n",
            "  Batch 3,040  of  3,282.    Elapsed: 0:05:17.\n",
            "  Batch 3,080  of  3,282.    Elapsed: 0:05:21.\n",
            "  Batch 3,120  of  3,282.    Elapsed: 0:05:25.\n",
            "  Batch 3,160  of  3,282.    Elapsed: 0:05:29.\n",
            "  Batch 3,200  of  3,282.    Elapsed: 0:05:33.\n",
            "  Batch 3,240  of  3,282.    Elapsed: 0:05:38.\n",
            "  Batch 3,280  of  3,282.    Elapsed: 0:05:42.\n",
            "\n",
            "  Average training loss: 0.71\n",
            "  Training epcoh took: 0:05:42\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "  Validation Loss: 0.63\n",
            "  Validation took: 0:02:12\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:31:34 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy: 0.79"
      ],
      "metadata": {
        "id": "7wOG_-X57zG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'rubert_weights.pth')"
      ],
      "metadata": {
        "id": "2IF2PfHa8ma-"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('rubert_weights.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obCPRz8TAu7W",
        "outputId": "8dd10ce8-fef3-4293-8687-17f3b6957c30"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "lkSUl53Ver_Q",
        "outputId": "2915977c-a475-436f-8af6-d0b9d469f742"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    -де             -д^е  target_idx       prediction  \\\n",
              "177319    возродившеюся   возрод^ившеюся           6   возрод^ившеюся   \n",
              "293072           гурвиц          г^урвиц           1          г^урвиц   \n",
              "1294652    рассердивший    рассерд^ивший           7    рассерд^ивший   \n",
              "141466        верталось       верт^алось           4       верт^алось   \n",
              "1600328        хлипкому        хл^ипкому           2        хл^ипкому   \n",
              "1002135  перфораторного  перфор^аторного           6  перфор^аторного   \n",
              "311153      дергавшиеся     д^ергавшиеся           1     дерг^авшиеся   \n",
              "606041   лавинообразную  лавинообр^азную           9  лавинообр^азную   \n",
              "663080          месящей         мес^ящей           3         мес^ящей   \n",
              "1623480      черствеешь      черств^еешь           6      черств^еешь   \n",
              "\n",
              "         is_right  \n",
              "177319          1  \n",
              "293072          1  \n",
              "1294652         1  \n",
              "141466          1  \n",
              "1600328         1  \n",
              "1002135         1  \n",
              "311153          0  \n",
              "606041          1  \n",
              "663080          1  \n",
              "1623480         1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4816c7ba-8a2e-4789-8207-ad6a680efc50\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>-де</th>\n",
              "      <th>-д^е</th>\n",
              "      <th>target_idx</th>\n",
              "      <th>prediction</th>\n",
              "      <th>is_right</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>177319</th>\n",
              "      <td>возродившеюся</td>\n",
              "      <td>возрод^ившеюся</td>\n",
              "      <td>6</td>\n",
              "      <td>возрод^ившеюся</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293072</th>\n",
              "      <td>гурвиц</td>\n",
              "      <td>г^урвиц</td>\n",
              "      <td>1</td>\n",
              "      <td>г^урвиц</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1294652</th>\n",
              "      <td>рассердивший</td>\n",
              "      <td>рассерд^ивший</td>\n",
              "      <td>7</td>\n",
              "      <td>рассерд^ивший</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141466</th>\n",
              "      <td>верталось</td>\n",
              "      <td>верт^алось</td>\n",
              "      <td>4</td>\n",
              "      <td>верт^алось</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1600328</th>\n",
              "      <td>хлипкому</td>\n",
              "      <td>хл^ипкому</td>\n",
              "      <td>2</td>\n",
              "      <td>хл^ипкому</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1002135</th>\n",
              "      <td>перфораторного</td>\n",
              "      <td>перфор^аторного</td>\n",
              "      <td>6</td>\n",
              "      <td>перфор^аторного</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311153</th>\n",
              "      <td>дергавшиеся</td>\n",
              "      <td>д^ергавшиеся</td>\n",
              "      <td>1</td>\n",
              "      <td>дерг^авшиеся</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>606041</th>\n",
              "      <td>лавинообразную</td>\n",
              "      <td>лавинообр^азную</td>\n",
              "      <td>9</td>\n",
              "      <td>лавинообр^азную</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>663080</th>\n",
              "      <td>месящей</td>\n",
              "      <td>мес^ящей</td>\n",
              "      <td>3</td>\n",
              "      <td>мес^ящей</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1623480</th>\n",
              "      <td>черствеешь</td>\n",
              "      <td>черств^еешь</td>\n",
              "      <td>6</td>\n",
              "      <td>черств^еешь</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4816c7ba-8a2e-4789-8207-ad6a680efc50')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4816c7ba-8a2e-4789-8207-ad6a680efc50 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4816c7ba-8a2e-4789-8207-ad6a680efc50');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Albert"
      ],
      "metadata": {
        "id": "wcS_w_3QC50x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"albert-base-v2\", \n",
        "    num_labels = max_len - 1,   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "model.to(device)\n",
        "optimizer = AdamW(model.parameters(),lr = 2e-5, eps = 1e-8)\n",
        "\n",
        "epochs = 1\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPWwFEIOC4lB",
        "outputId": "bd362b3d-36d5-42d2-e40f-e8d5685bbe1c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type albert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "Some weights of the model checkpoint at albert-base-v2 were not used when initializing BertForSequenceClassification: ['albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight', 'predictions.LayerNorm.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias', 'albert.embeddings.position_embeddings.weight', 'predictions.decoder.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias', 'predictions.dense.bias', 'albert.pooler.weight', 'albert.encoder.embedding_hidden_mapping_in.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.weight', 'albert.encoder.embedding_hidden_mapping_in.weight', 'predictions.dense.weight', 'predictions.bias', 'albert.embeddings.token_type_embeddings.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias', 'albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight', 'predictions.LayerNorm.bias', 'predictions.decoder.bias', 'albert.pooler.bias', 'albert.embeddings.word_embeddings.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight', 'albert.encoder.albert_layer_groups.0.albert_layers.0.ffn_output.bias', 'albert.embeddings.LayerNorm.bias', 'albert.embeddings.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import Accelerator\n",
        "import bitsandbytes as bnb\n",
        "from torch import nn\n",
        "from transformers.trainer_pt_utils import get_parameter_names\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "default_args = {\n",
        "    \"output_dir\": \"tmp\",\n",
        "    \"evaluation_strategy\": \"steps\",\n",
        "    \"num_train_epochs\": 1,\n",
        "    \"log_level\": \"error\",\n",
        "    \"report_to\": \"none\",\n",
        "}\n",
        "training_args = TrainingArguments(per_device_train_batch_size=32, **default_args)\n",
        "\n",
        "decay_parameters = get_parameter_names(model, [nn.LayerNorm])\n",
        "decay_parameters = [name for name in decay_parameters if \"bias\" not in name]\n",
        "optimizer_grouped_parameters = [\n",
        "    {\n",
        "        \"params\": [p for n, p in model.named_parameters() if n in decay_parameters],\n",
        "        \"weight_decay\": training_args.weight_decay,\n",
        "    },\n",
        "    {\n",
        "        \"params\": [p for n, p in model.named_parameters() if n not in decay_parameters],\n",
        "        \"weight_decay\": 0.0,\n",
        "    },\n",
        "]\n",
        "\n",
        "optimizer_kwargs = {\n",
        "    \"betas\": (training_args.adam_beta1, training_args.adam_beta2),\n",
        "    \"eps\": training_args.adam_epsilon,\n",
        "}\n",
        "optimizer_kwargs[\"lr\"] = training_args.learning_rate\n",
        "adam_bnb_optim = bnb.optim.Adam8bit(\n",
        "    optimizer_grouped_parameters,\n",
        "    betas=(training_args.adam_beta1, training_args.adam_beta2),\n",
        "    eps=training_args.adam_epsilon,\n",
        "    lr=training_args.learning_rate,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hI_52-nVCjG",
        "outputId": "79e22bbd-3a69-4d1d-d54d-14d10c227780"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin /usr/local/lib/python3.9/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.9/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: /usr/lib64-nvidia did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('http'), PosixPath('8013'), PosixPath('//172.28.0.1')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-s-3egyee5xpnv4j --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true'), PosixPath('--listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//ipykernel.pylab.backend_inline'), PosixPath('module')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
            "Either way, this might cause trouble in the future:\n",
            "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
            "  warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "\n",
        "accelerator = Accelerator(mixed_precision=\"fp16\")\n",
        "model_, optimizer, train_dataloader = accelerator.prepare(model, adam_bnb_optim, train_dataloader)\n"
      ],
      "metadata": {
        "id": "bT4cRLN6VM2c"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "44HJl-HiIl6_"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_.train()\n",
        "for step, batch in enumerate(tqdm(train_dataloader), start=1):\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    output = model_(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "    loss = output.loss / training_args.gradient_accumulation_steps\n",
        "    accelerator.backward(loss)\n",
        "    if step % training_args.gradient_accumulation_steps == 0:\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9044e3e2ba7742898681f8c2cab10e1c",
            "e4e3148628544961a843b296135d5fb5",
            "3d522b73fae649dab46588e2e764aae4",
            "c5d4790e629f4709aa45c5158ef3adf4",
            "76d589e8d6634a7ea67920d26d5bec3e",
            "b02cc6c2bb6040d1a1082311917cd293",
            "9d47441331ef4c6a98cbe5e585de060a",
            "0b7d09f100dc4e17b217a84bd767c2c1",
            "0d6f28e70b2247eca1ec5cfa2d36bdd7",
            "d65b8539e6de45d89b308858cf67ec22",
            "967cc44586cc4c988237c34ce37cf8c6"
          ]
        },
        "id": "MyEf7WpMVP0c",
        "outputId": "f7d842ac-a733-4817-94c5-bf2ff0c5613d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/13126 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9044e3e2ba7742898681f8c2cab10e1c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# val\n",
        "print(\"\\nRunning Validation...\")\n",
        "\n",
        "t0 = time.time()\n",
        "model.eval()\n",
        "\n",
        "total_eval_accuracy = 0\n",
        "total_eval_loss = 0\n",
        "nb_eval_steps = 0\n",
        "\n",
        "for batch in validation_dataloader:\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    \n",
        "    with torch.no_grad():        \n",
        "        output = model_(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask, labels=b_labels)\n",
        "        \n",
        "    total_eval_loss += output.loss.item()\n",
        "\n",
        "    logits = output.logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "    \n",
        "\n",
        "avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "validation_time = format_time(time.time() - t0)\n",
        "\n",
        "print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "print(\"  Validation took: {:}\".format(validation_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmST0SHzWXUf",
        "outputId": "286195fc-2e5f-4fbd-ebfc-54470b7f3ece"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.01\n",
            "  Validation Loss: nan\n",
            "  Validation took: 0:19:31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_model(model, optimizer, scheduler, epochs)"
      ],
      "metadata": {
        "id": "xYkIhwDfAu0e"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_.state_dict(), 'albert_weights.pth')"
      ],
      "metadata": {
        "id": "KcfI0_ETAux8"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_.load_state_dict(torch.load('albert_weights.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDf-rL5MAuuw",
        "outputId": "b003c202-654b-4222-b583-43c3d7fcf54f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(model_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "U7F9cga4HCEd",
        "outputId": "08c14f5d-6016-4e64-a77e-babc9423a02c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   -де            -д^е  target_idx      prediction  is_right\n",
              "331232   додумывавшими  дод^умывавшими           3  ^додумывавшими         0\n",
              "647800        маринова       мар^инова           3       ^маринова         0\n",
              "431832    зарядившимся   заряд^ившимся           5   ^зарядившимся         0\n",
              "424960      заполучаем     заполуч^аем           7     ^заполучаем         0\n",
              "1643854          шлихи          шлих^и           4          ^шлихи         0\n",
              "442768        затечешь       затеч^ешь           5       ^затечешь         0\n",
              "563471     комплементе    комплем^енте           7    ^комплементе         0\n",
              "819140    обмельчавшей   обмельч^авшей           7   ^обмельчавшей         0\n",
              "1653022       щурившим       щ^урившим           1       ^щурившим         0\n",
              "1363772    сдружаетесь    сдруж^аетесь           5    ^сдружаетесь         0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8309abac-7c86-49e9-97db-ed9d46306bac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>-де</th>\n",
              "      <th>-д^е</th>\n",
              "      <th>target_idx</th>\n",
              "      <th>prediction</th>\n",
              "      <th>is_right</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>331232</th>\n",
              "      <td>додумывавшими</td>\n",
              "      <td>дод^умывавшими</td>\n",
              "      <td>3</td>\n",
              "      <td>^додумывавшими</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>647800</th>\n",
              "      <td>маринова</td>\n",
              "      <td>мар^инова</td>\n",
              "      <td>3</td>\n",
              "      <td>^маринова</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431832</th>\n",
              "      <td>зарядившимся</td>\n",
              "      <td>заряд^ившимся</td>\n",
              "      <td>5</td>\n",
              "      <td>^зарядившимся</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>424960</th>\n",
              "      <td>заполучаем</td>\n",
              "      <td>заполуч^аем</td>\n",
              "      <td>7</td>\n",
              "      <td>^заполучаем</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1643854</th>\n",
              "      <td>шлихи</td>\n",
              "      <td>шлих^и</td>\n",
              "      <td>4</td>\n",
              "      <td>^шлихи</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>442768</th>\n",
              "      <td>затечешь</td>\n",
              "      <td>затеч^ешь</td>\n",
              "      <td>5</td>\n",
              "      <td>^затечешь</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>563471</th>\n",
              "      <td>комплементе</td>\n",
              "      <td>комплем^енте</td>\n",
              "      <td>7</td>\n",
              "      <td>^комплементе</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>819140</th>\n",
              "      <td>обмельчавшей</td>\n",
              "      <td>обмельч^авшей</td>\n",
              "      <td>7</td>\n",
              "      <td>^обмельчавшей</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1653022</th>\n",
              "      <td>щурившим</td>\n",
              "      <td>щ^урившим</td>\n",
              "      <td>1</td>\n",
              "      <td>^щурившим</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1363772</th>\n",
              "      <td>сдружаетесь</td>\n",
              "      <td>сдруж^аетесь</td>\n",
              "      <td>5</td>\n",
              "      <td>^сдружаетесь</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8309abac-7c86-49e9-97db-ed9d46306bac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8309abac-7c86-49e9-97db-ed9d46306bac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8309abac-7c86-49e9-97db-ed9d46306bac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deberta"
      ],
      "metadata": {
        "id": "QYRVwG3ENt9_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MEfjrwZZHCCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DoTWbzFIHB_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "In2BKayGHB60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QcKEfNpJHB36"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}